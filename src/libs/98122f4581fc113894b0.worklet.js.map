{"version":3,"file":"98122f4581fc113894b0.worklet.js","mappings":"AA0BA,MAAMA,UAA6BC,sBAI/BC,aAA6B,GACpBC,wBAA0B,GAC1BC,wBAA0B,EACnCC,YAAa,EAMbC,YAAYC,GACRC,MAAMD,GAENE,KAAKC,KAAKC,UAAYF,KAAKG,UAW/BA,UAAaC,IAET,MAAMC,EAAa,IAAIC,WAAWF,EAAQG,MAI1C,GAHAP,KAAKP,aAAae,KAAKH,GAGnBL,KAAKP,aAAagB,OAAST,KAAKN,wBAGhC,KAAOM,KAAKP,aAAagB,OAAST,KAAKL,yBACnCK,KAAKP,aAAaiB,QAKrBV,KAAKJ,YACFI,KAAKP,aAAagB,QAAUT,KAAKL,0BAEjCK,KAAKJ,YAAa,IAgB9Be,QAAQC,EAA6BC,GAUjC,IAAIR,EASJ,GARIL,KAAKJ,aACLS,EAAaL,KAAKP,aAAaiB,aACZI,IAAfT,IAEAL,KAAKJ,YAAa,MAIrBiB,GAAeA,EAAW,IAAOA,EAAW,GAAG,IAAOA,EAAW,GAAG,IAErE,OAAO,EAGX,MAEME,EAAcC,KAAKC,IAAIJ,EAAW,GAAG,GAAGJ,OAAQJ,EAAaA,EAAWI,OAAS,EADnD,KAG9BS,EAASL,EAAW,GAC1B,IAAK,IAAIM,EAAU,EAAGA,EALD,EAKyBA,IAAW,CACrD,MAAMC,EAAUF,EAAOC,GACvB,IAAK,IAAIE,EAAI,EAAGA,EAAIN,EAAaM,IAAK,CAClC,IAAIC,EAAS,EACTjB,IACAiB,EAASjB,EAAe,EAAJgB,EAAQF,GAhCnB,OAkCbC,EAAQC,GAAKC,GAIrB,OAAO,GAIfC,kBAAkB,kCAAmChC","sources":["webpack://@vircadia/web-sdk/./src/domain/worklets/AudioOutputProcessor.ts"],"sourcesContent":["//\n//  AudioOutputProcessor.ts\n//\n//  Created by David Rowe on 14 Sep 2021.\n//  Copyright 2021 Vircadia contributors.\n//\n//  Distributed under the Apache License, Version 2.0.\n//  See the accompanying file LICENSE or http://www.apache.org/licenses/LICENSE-2.0.html\n//\n\n\n/*@devdoc\n *  The <code>AudioOutputProcessor</code> class implements a Web Audio\n *  {@link https://developer.mozilla.org/en-US/docs/Web/API/AudioWorkletProcessor|AudioWorkletProcessor} that outputs SDK audio\n *  to a MediaStream. It is used as a node in a Web Audio graph in {@link AudioOutput}.\n *  <p>It runs on its own thread and uses a ring buffer to buffer an amount of data received to play in order to help maintain a\n *  smooth output stream.</p>\n *  <p>C++: <code>N/A</code></p>\n *  @class AudioOutputProcessor\n *  @param {AudioWorkletNodeOptions} options -\n *    {@link https://developer.mozilla.org/en-US/docs/Web/API/AudioWorkletProcessor/AudioWorkletProcessor|AudioWorkletProcessor}\n *    options.\n *\n *  @property {MessagePort} port - Used to communicate between the AudioWorkletProcessor object and its internal code. See\n *    {@link https://developer.mozilla.org/en-US/docs/Web/API/AudioWorkletNode/port|AudioWorkletNode.port}.\n */\nclass AudioOutputProcessor extends AudioWorkletProcessor {\n\n    // Buffer blocks of audio data so that they can be played back smoothly.\n    // FIXME: All these fields should be private (#s) but Firefox is handling transpiled code with them (Sep 2021).\n    _audioBuffer: Int16Array[] = [];\n    readonly MAX_AUDIO_BUFFER_LENGTH = 16;  // The maximum number of audio blocks to buffer.\n    readonly MIN_AUDIO_BUFFER_LENGTH = 4;  // The minimum number of audio blocks to have before starting to play them.\n    _isPlaying = false;  // Is playing audio blocks from the buffer.\n\n    // _lastAudioBufferLength = 0;\n\n    // The typings aren't complete for the Web Audio API (Sep 2021), hence the ESlint and TypeScript disablings.\n\n    constructor(options?: AudioWorkletNodeOptions) {\n        super(options);\n\n        this.port.onmessage = this.onMessage;\n    }\n\n    /*@devdoc\n     *  Takes incoming audio blocks posted to the audio worklet's message port and queues them in a ring buffer for playing.\n     *  If too many audio blocks are queued, some of the older ones are discarded.\n     *  If too few audio blocks are queued, playing is paused while a minimum number of audio blocks are accumulated.\n     *  @function AudioOutputProcessor.onMessage\n     *  @param {MessageEvent} message - The message posted to the audio worklet, with <code>message.data</code> being an\n     *      <code>Int16Array</code> of PCM audio samples, ready to play.\n     */\n    onMessage = (message: MessageEvent) => {\n        // Buffer the new block of audio samples.\n        const audioBlock = new Int16Array(message.data);\n        this._audioBuffer.push(audioBlock);\n\n        // If we've reached the maximum buffer size, skip some of the audio blocks.\n        if (this._audioBuffer.length > this.MAX_AUDIO_BUFFER_LENGTH) {\n            // console.log(\"AudioOutputProcessor: Discard\", this._audioBuffer.length - this.MIN_AUDIO_BUFFER_LENGTH,\n            //     \"blocks\");\n            while (this._audioBuffer.length > this.MIN_AUDIO_BUFFER_LENGTH) {\n                this._audioBuffer.shift();\n            }\n        }\n\n        // Start playing if not playing and we now have enough audio blocks.\n        if (!this._isPlaying) {\n            if (this._audioBuffer.length >= this.MIN_AUDIO_BUFFER_LENGTH) {\n                // console.log(\"AudioOutputProcessor: Start playing\");\n                this._isPlaying = true;\n            }\n        }\n    };\n\n\n    /*@devdoc\n     *  Called by the Web Audio pipeline to provide the next block of audio samples to play. The next audio block from the ring\n     *  buffer is played if one is available and playing is not paused, otherwise a block of silence is played. The Int32 values\n     *  from the ring buffer are converted to Float32 values.\n     *  @param {Float32Array[][]} inputList - Input PCM audio samples. <em>Not used.</em>\n     *  @param {Float32Array[][]} outputList - Output PCM audio samples.\n     *  @param {Record<string, Float32Array>} parameters - Processing parameters. <em>Not used.</em>\n     */\n    // eslint-disable-next-line\n    // @ts-ignore\n    process(inputList: Float32Array[][], outputList: Float32Array[][] /* , parameters: Record<string, Float32Array> */) {\n\n        const FLOAT_TO_INT = 32767;\n\n        // if (this._audioBuffer.length !== this._lastAudioBufferLength) {\n        //     console.log(\"Buffer length =\", this._audioBuffer.length);\n        //     this._lastAudioBufferLength = this._audioBuffer.length;\n        // }\n\n        // Grab the next block of audio to play.\n        let audioBlock: Int16Array | undefined = undefined;\n        if (this._isPlaying) {\n            audioBlock = this._audioBuffer.shift();\n            if (audioBlock === undefined) {\n                // console.log(\"AudioOutputProcessor: Stop playing\");\n                this._isPlaying = false;\n            }\n        }\n\n        if (!outputList || !outputList[0] || !outputList[0][0] || !outputList[0][1]) {\n            // console.log(\"Early return!\");\n            return true;\n        }\n\n        const channelCount = 2;\n        const EXPECTED_AUDIO_BLOCK_FRAMES = 128;\n        const sampleCount = Math.min(outputList[0][0].length, audioBlock ? audioBlock.length / 2 : EXPECTED_AUDIO_BLOCK_FRAMES);\n\n        const output = outputList[0];\n        for (let channel = 0; channel < channelCount; channel++) {\n            const samples = output[channel] as Float32Array;\n            for (let i = 0; i < sampleCount; i++) {\n                let sample = 0;\n                if (audioBlock) {\n                    sample = audioBlock[i * 2 + channel] as number / FLOAT_TO_INT;\n                }\n                samples[i] = sample;\n            }\n        }\n\n        return true;\n    }\n}\n\nregisterProcessor(\"vircadia-audio-output-processor\", AudioOutputProcessor);\n"],"names":["AudioOutputProcessor","AudioWorkletProcessor","_audioBuffer","MAX_AUDIO_BUFFER_LENGTH","MIN_AUDIO_BUFFER_LENGTH","_isPlaying","constructor","options","super","this","port","onmessage","onMessage","message","audioBlock","Int16Array","data","push","length","shift","process","inputList","outputList","undefined","sampleCount","Math","min","output","channel","samples","i","sample","registerProcessor"],"sourceRoot":""}